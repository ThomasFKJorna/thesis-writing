#+title: FQHE/anyon chapter
#+roam_tags: chapter anyons FQHE
#+OPTIONS: H:6 title:nil
#+latex_header: \usepackage{braket}

* The Fractional quantum hall effect and its discontents

# convince the reader that what you're saying is worthwhile

So, now that we have gained a high-level idea of idealizations, the question is: which idealizations are worth looking at? We have seen some standard examples such as air resistance, but those turned out to be easily understood as approximations rather than idealizations, for when we want to predict the velocity of a falling ball it does not really matter whether there is no air resistance or $0$ air resistance, so we can freely move between (demote and promote) the idealized model (the ball falling in a vacuum) and the approximate propositions about our actual system (for the first seconds of the fall of the ball its speed $\approx gt$).

We must keep in mind, however, that whether an idealization proves problematic depends not only on the specific model constructed, but crucially on the specific properties we are idealizing (away) and what properties of the target system we care about preserving. In the case of the ball, we are primarily interested in its velocity, which is (at least for the first few seconds) only marginaly affected by the idealization.

Imagine instead another researcher, Andreas, who is a bit of an odd fellow. Andreas does not care in the least what the velocity of the ball is, it's all the same to them. What Andreas /is/ interested in is whether the ball will continue to accelerate indefenitely or whether the ball will reach a stable velocity at some point, whatever that may be, Andreas doesn't care. For Andreas, this model would not at all do as an idealization, as the ball falling in air resistance will never reach a stable velocity, always accelerating, accelerating...

Therefore, it might not seem wise to argue in detail about what the status of any given statement, equation or theory /is/, as one man's approximation is another man's idealization. The whole field of study could perhaps just be summed up with "it depends", another philosophical debate has been explained away and Wittgensteinians around the world rejoice.

As big of a fan of ol' Ludwig I am, I do think there is sufficient reason not to treat this as just another language game and that at the very least there are some unexplored areas left to explore. Two possibilities lie before us. Firstly we could argue that a hard distinction /can/ be made between idealizations and approximations. For one, Norton explicitly claimed that his distinction was not meant as the be all end all definition of both terms, but merely a /characterization/, which, while a fair description of Norton's work here, does seem like the philosopher's equivalent of a Youtuber claiming "no copyright infringement intended" after using a Metallica song in their intro: you might not want people to take it a certain way, but you should have expected they would.

However, even disregarding Norton's disclaimer, it does not quite feel in the spirit of this thesis to attempt to construct a rigorous distinction between two sketchy, dare I say "vague" concepts. Instead, to somewhat placate those pesky Wittgensteinians, I will go for the second option, namely to discuss a purported idealization in which the property under question is such that we all agree to care about the outcome of our scrutinizing: the very existence of the system/property/... to begin with! And what could be more interesting (to physicists, and therefore the world) than the existence of  a whole class of new particles?

** Anyons

Anyons are a theorized and alledgedly observed new type of particles. Up until their theorizing/observation, physics squarely placed particles in two types: [[file:20210218153430-fermions.org][fermions]] such as electrons, neutrinos and quarks, and [[file:20210218153456-bosons.org][bosons]] such as photons, protons and the Higgs particle. What unites all these particles is that if you have two of them, they are /indistinguishable/ from one another, meaning that when you find yourself in the unenviable position of calculating with more than one particle, you have to account for the fact that it is /impossible/ to keep the two apart. We call this "accounting for" /phase/, which we multiply with the state of the system anytime we exchange the two particles.  By the spin-statistics theorem, the phase of a particle also tells us something about their [[file:20210223152109-spin.org][spin]].[fn:3]  "Thus" we have fermions with spin of integer multiples of $\frac{1}{2}$, and bosons with integer spin.

We will see why this is the case in a second, but the important disclaimer to the above result is that it only holds in $3D$ and higher. There exists a way to get around the inevitability of two types of particles in $2D$, such that we can show that there could be particles which have different statistics and could take on /any/ spin, aptly named [[file:20210218152909-anyons.org][anyons]].

What makes them interesting as a case study here is that the commonly accepted explanation for anyons states that they are not able to exist in 3 dimensions, only being possible in 2 dimensions. This is very intersting, because the world we know is 3D, how can it possibly be that these particles are 2D?

The reason this is especially interesting is that were this to be so, we would have a very clearly observable case of a discontinuous change of a very continuous parameter: the crossing of the boundary between 2D and 3D. This boundary crossing has a couple of different qualities that make it an excellent case study

1. The change is rather dramatic: getting rid of a whole dimension is no easy feat.
2. The explanation for anyons is somewhat controversial, meaning that there is a lot of different viewpoints
3. The difficulty of this problem is usually waved away by physicists by saying that the problem is actually just /effectively 2D/, meaning that the system is 3D but just behaves in a 2D fashion. This is usually not substantiated much, however.

Remember the main trilemma we find ourselves in when discussing such a boundary. If we have a binary property dependent on a continuously varying parameter, we (or so I wish to show) have one of three choices for drawing a line
1. The parameter $x$ is not a continuous but a discrete parameter. This allows us to draw the line with arbitrary precision somewhere
2. The  parameter $x$ is continuous, and either $\not P$ or $P$ is true $\forall x$
3. The parameter $x$ is continuous and we do not really care about whether $P \or \not P$ is /really/ true, nor care about where the line is really drawn, we just have cases where the line is definitely drawn and once where it is unclear. We give up the binary nature of $P$.

The case of the anyon presents itself as either 2/3 (The system is not 2D but 3D and effectively 2D) or as one which falls outside of these categorizations, that is: it's interesting. The former is what physicists usually argue but do not practice (they do not provide an adequate characterization, as I shall show) while the latter is the argument made by  cite:Shech2019, which I will examine in great detail in the rest of this chapter.

# This might still annoy some but I don't care this is enough warmup.



That's whats at stake in the qhe, between 2d and 3d


** Sorry, what was this about the quantum hall effect again?

The astute reader may have noticed that we have not yet referred to the title of this chapter at all! What is this quantum hall effect?

This is true: anyons were independently theorized by .... in 1978, and their existence in 2D can be predicted using merely topological

I will argue in the

The FQHE does not per se rely on anyons for its explanation, rather it shows that the mechanism which gives rise to the effect are anyonic interactions.

I argue that we cannot look at the way anyons are theorized through constructing configuration spaces without looking at how this might physically manifest itself in the lab.

One objection to this reasoning is that it would bias the investigation in "my" favor, namely that I would think the explanation to be unsatisfactory regardless because we cannot manifest (such) a 2D system in a 3D world. This is a fair concern, so I propose a "bet" of sorts: if I am not able to find and alternative characterization of how effective 2D systems would give rise to anyons, I will accept that the system is exactly and not approximately 2D.
Having 2D systems, while not fitting in our current worldview as snugly as I would like, would open the door to a lot of interesting new physics.

On the other hand, if I do succeed in providing an agreeable characterization of effective 2D, then this would deepen our understanding of such effects much more, open up that black box so to say, and perhaps allow us to more easily construct such systems later due to our deepened understanding.

=JUSTIFY BETTER=
Finally, I wish to address the quantum hall effect itself /first/, before diving into the purported explanation of anyons. If we were to examine the anyons first .....


* The explanation of anyons

#+include: "./20210402123014-the_configuration_space_explanation_chapter.org" :minlevel 2

[[file:20210402123014-the_configuration_space_explanation_chapter.org][The configuration space explanation chapter]]
#+transclude: t [[file:20210402123014-the_configuration_space_explanation_chapter.org][The configuration space explanation chapter]]

#+include: "./20210414134239-if_particles_cannot_be_closer_than_the_thickness_of_the_strip_the_configuration_space_is_approximately_2d.org" :minlevel 2
[[file:20210414134239-if_particles_cannot_be_closer_than_the_thickness_of_the_strip_the_configuration_space_is_approximately_2d.org][If particles cannot be closer than the thickness of the strip, the configuration space is approximately 2D]]
#+transclude: t [[file:20210414134239-if_particles_cannot_be_closer_than_the_thickness_of_the_strip_the_configuration_space_is_approximately_2d.org][If particles cannot be closer than the thickness of the strip, the configuration space is approximately 2D]]

#+begin_comment
#+
[[file:20210414155705-proof_ballspace_is_not_simply_connected.org][Proof ballspace is not simply connected]]

#+transclude: t :level 2
[[file:20210414155524-how_does_qm_work_in_non_simply_connected_space.org][How does QM work in non-simply connected space?]]

#+transclude: t
[[file:20210414155618-how_to_justify_particles_not_being_able_to_escape.org][How to justify particles not being able to escape]]
#+end_comment

#+begin_comment
whitespace between sections



































#+end_comment

*  The Quantum Hall Effect

Now that we have gained some high level understanding of the interesting difficulties concerning anyons, we now turn to the actually important part: examining the actual effect.

** Once again, what is it

*** Classical Hall effect

[[file:20210218152105-classical_hall_effect.org][classical hall effect]]

=Here’s the set-up. We turn on a constant magx I H V B, B pointing in the z-direction. Meanwhile, the electrons are restricted to move only in the (x, y)plane. A constant current I is made to flow in the x-direction. The Hall effect is the statement that this induces a voltage VH (H is for “Hall”) in the y-direction. This is shown in the figure= ref:chetong.
#+caption: Classical Hall effect
#+attr_latex: scale=0.75
#+label: fig:chetong
[[./media/chetong.png]]

Since the voltage $V_H$ linearly depends on the Lorentz force, which linearly depends on the strength of the magnetic field $B$, $V_H$ linearly depends on $B$ and thus, classically, we expect the graph to look like Figure ref:linresistance. Similarly, we don't expect the resistance along the strip $\rho_{xx}$ to vary either. =Bit more explanation for why we do not expect this=
#+caption: caption Linear Resistance
#+attr_latex: scale=0.75
#+label: fig:linresistance
[[./media/linresistance.png]]

Note that for computational ease we are measuring and calculating the /resistivity/ along a certain axis rather than the voltage.

However, as is often the case in physics, systems can behave rather differently from our classical expectations when put in extreme circumstances. These circumstances, in this case, include extremely low temperatures ($<2K$), strong magnetic fields ($>>1T$) and rather pure samples (but, as we shall see, not too pure either.) When these conditions are met, the graph looks something more like Figure ref:ifqhe

#+caption: Integer and fractional effects
#+attr_latex: scale=0.75
#+label: fig:ifqhe
[[./media/fqhe.png]]

After a certain magnetic field strength has been reached, these plateaux start to show up. The question then of course is: why?


*** Preliminaries

 To understand why the QHE arises, we must first grasp the fundamental mechanism through which it can arise in the first place, namely the quantization of energy states of electrons when subject to a constant magnetic field. These specific energy eigenstates are called /[[file:20210223154027-landau_levels.org][Landau levels]]/, unsurprisingly first described by Landau, and deriving and gaining a general understanding of them will be our first task. =Badly written=


# **** Quantization
# Not necessary according to Guido, which I agree with
#+begin_comment
=I'm over explaining here=
The (literal) textbook approach we will follow here is describing the classical system first and then quantizing it. The rough steps required are to first compute the [[file:20210223154511-lagrangian.org][Lagrangian]] of the classical system, use that to compute its [[file:20210317122727-hamiltonian.org][Hamiltonian]], from which we can derive the [[file:20210317122807-poisson_brackets.org][Poisson Brackets]]. Then, we treat the Hamiltonian as if it were quantum, use the Poisson Brackets as the [[file:20210317122922-canonical_commutation_relation.org][Canonical Commutation Relation,]] rewrite the Hamiltonian in a form we understand (as always, the [[file:20210317123047-harmonic_oscillator.org][Harmonic Oscillator]]), and use that Hamiltonian to construct the [[file:20210317123126-hilbert_space.org][Hilbert Space]] from which we can read the energy levels. Sounds simple enough, right?


 First, let us recap the Lagrangian of a particle in a magnetic field.
$L = T - V$
$T=1/2 m\dot{x}^2$
$V = e \dot{x}\cdot \textbf{A}$

\begin{equation}
    L=\frac{1}{2}m \dot{\textbf{x}}^{2}-e \dot{\textbf{x}}\cdot \textbf{A}
    \label{eq:lagrmag}
\end{equation}


 From here we can derive the Hamiltonian
\[H= \dot{\textbf{x}} \cdot \textbf{P} -L = \dot{\textbf{x}} \frac{\partial L}{\partial \dot{\textbf{x}}} - L = .....    \]
\begin{equation}
   H = \frac{1}{2m} (\textbf{p} + e \textbf{A})^{2}
    \label{eq:classHamMag}
\end{equation}

 Using the Hamiltonian it is easy to derive the Poisson Bracket structure.
Little sidenote about why that is important.
\begin{equation}
    \{F(x,y),G(x,y)\}=\frac{\partial F}{\partial x}\frac{\partial G}{\partial y} - \frac{\partial F}{\partial y}\frac{\partial G}{\partial x}
    \label{eq:poissonbrackets}
\end{equation}


\begin{equation}
    \{x_i, p_j\}=\delta_{ij} \text{   with    } \{x_i,x_j\}=\{p_i,p_j\}=0
    \label{eq:poissonmag}
\end{equation}

Coool


  Now we can move on to the quantum side, which means we can take over \ref{eq:magham} and substitute the functions for quantum operators.
\begin{equation}
    H=\frac{1}{2m}(\hat{\textbf{p}} + e \hat{\textbf{A}} )^{2}
    \label{eq:quantumMagHam}
\end{equation}

We take Gauge $\nabla \times \hat{\textbf{A}}= B \hat{z}$

And get canonical commutation relations

\begin{equation}
    [x_i, p_j]=i\hbar\delta_{ij} \text{   with   } [x_i, x_j]=[p_i,p_j]=0
    \label{eq:ccr}
\end{equation}

Then we do raising lowering, find the hamiltonian and then

\begin{equation}
    E_n=\hbar\omega_B \Big(n+\frac{1}{2} )\quad n \in \mathbb{N}
    \label{eq:landaulevels}
\end{equation}

Astute readers might have noticed that, suprisingly, the spin of the particles has not been mentioned once so far! This is because we can relatively safely neglect it as a good approximation, as the effect of spin on the energy states smoothly becomes less and less prominent the higher the strength of the magnetic field is.

An additionally seemingly important detail is the fact that the Hall System is taken to be in 2D from the start.

#+end_comment


***  Integer vs Fractional

There are not one but two quantum Hall effects: the integer and the fractional. Both are explained by somewhat similar mechanisms, but only in the latter do we speak of anyons, so the FQHE will have our focus. However, it is worth briefly going over the integer version, as it provides some broad intuition for why the plateaux are at these points, and why there are plateaux in the first place. The integer explanation, however, will depend on two facts which necessarily do not apply to its fractional cousin: electron interaction are ignored, and the sample needs to be not too clean. Because of this first idealization, we are able to describe the IQHE much more rigorously than the FQHE as well.


#+BEGIN_COMMENT
[[file:20210219124712-the_quantum_hall_effect_has_two_variations_integer_and_fractional.org][the quantum hall effect has two variations, integer and fractional]]
#+END_COMMENT
**  The Integer Quantum Hall Effect



#+caption: The Integer Quantum Hall Effect
#+attr_latex: scale=0.75
#+label: fig:iqhe
[[./media/iqhe2.png]]

The *Integer Quantum Hall Effect* (IQHE), whose resistivity graph can be seen in ref:fig:iqhe, is the appearance of plateaux in the transversal resistivity of a conducting strip at integer multiples of the /[[file:20210219125647-quantum_of_resistance.org][quantum of resistance]]/    $R_q=e^2\hbar/2\pi$, indicated by the $i$s in ref:fig:iqhe.

The IQHE has several other interesting features which will come into play later:
a) The location of the plateaux appears to be independent of the specific material
b) The material must have some impurities, it cannot be "too clean"
c) =The material must be rather thin. In fact, we take the material to be so thin that it becomes $2D$. This choice will come back to haunt us, but it is (for now) the only way of understanding the effect.=

   Naturally, a physicist, after obtaining these results, would ask: why are these plateaux there? We can split this question into two subquestions:
1. Why are there plateaux at all?
2. Why are they at these regular, integer-multiple levels?

Upon seeing ref:fig:iqhe, one might make a natural first guess to an answer to /2/  that these plateaux correspond to the different energy levels of the electrons of the system. In fact, one would be correct! While not trivial, it turns out that these plateaux correspond to the spectrum of a charged particle in a magnetic field, whose energy levels are called [[file:20210223154027-landau_levels.org][Landau levels]]. Deriving these will be the first step to understanding the Quantum Hall Effect as a whole.

***  Landau Levels

=Our task is to solve for the spectrum and wavefunctions of the quantum Hamiltonian,
$H 1 2m (p + eA)2$=

=Since the particle is restricted to lie in the plane, we write x = (x, y). Meanwhile, we take the magnetic field to be constant and perpendicular to this plane, ∇ × A = Bˆ z.=

To make our lives somewhat easier, we define the /mechanical momentum/ to be

\[\hat{\mathbf{\pi}}=\hat{\mathbf{p}} + e \hat{\mathbf{A}} \]
which satisfy the commutation relations
\begin{equation}
[\hat{\mathbf{\pi_x}}, \hat{\mathbf{\pi_y}}] = \hat{\mathbf{\pi_x}} \hat{\mathbf{\pi_y}} - \hat{\mathbf{\pi_y}} \hat{\mathbf{\pi_x}}   = -ie\hbar B
    \label{eq:momcom}
\end{equation}

These allow us to define raising and lowering operators
=At this point we introduce new variables. These are raising and lowering operators, entirely analogous to those that we use in the harmonic oscillator. They are defined by=
\[a= \frac{1}{\sqrt{2e\hbar B}} (\pi_x − i\pi_y) \quad a^\dagger = 1\frac{1}{\sqrt{2e\hbar B}} (\pi_x + i\pi_y)\]

The commutation relations for π then tell us that a and a† obey
\[[a, a^\dagger] = 1\]

=which are precisely the commutation relations obeyed by the raising and lowering operators of the harmonic oscillator. Written in terms of these operators, the Hamiltonian (1.13) even takes the same form as that of the harmonic oscillator=
\[H= 1 2m π · π = ~ωB ( a†a + 1 2 )\]
where $ωB = eB/m$ =is the cyclotron frequency that we met previously (1.3). Now it’s simple to finish things off. We can construct the Hilbert space in the same way as the harmonic oscillator: we first introduce a ground state=|0〉 obeying ==== =a|0〉 = 0 and build the rest of the Hilbert space by acting with a†, a†|n〉 = √n + 1|n + 1〉 and a|n〉 = √n|n − 1〉 The state |n〉 has energy En = ~ωB ( n+ 1 2 ) n ∈ N (1.16) We learn that in the presence of a magnetic field, the energy levels of a particle become equally spaced, with the gap between each level proportional to the magnetic field B. The energy levels are called Landau levels. N==

*Unlike the Harmonic oscillator, which concerns a $1D$ system with unique energy eigenstates, the Landau levels are not at all unique and extremely degenerate.*

[[file:20210223163548-landau_states_have_a_large_degeneracy.org][Landau states have a large degeneracy]]
#+transclude: t [[file:20210223163548-landau_states_have_a_large_degeneracy.org][Landau states have a large degeneracy]]


**** Finding the Landaus

     We have found /that/ the spectrum is discrete and that the eigenstates are widly degenerate, but we have not yet found a wavefunction nor energy for said eigenstates, which would be nice to have for saying anything concrete about the system.

=To find wavefunctions corresponding to the energy eigenstates, we first need to specify a gauge potential A such that ∇ × A = Bˆ z There is, of course, not a unique choice. In this section and the next we will describe two different choices of A. In this section, we work with the choice A = xB ˆ y (1.17) This is called Landau gauge. Note that the magnetic field B is invariant under both translational symmetry and rotational symmetry in the (x, y)-plane. However, the choice of A is not; it breaks translational symmetry in the x direction (but not in the y direction) and rotational symmetry. This means that, while the physics will be invariant under all symmetries, the intermediate calculations will not be manifestly invariant. This kind of compromise is typical when dealing with magnetic field. The Hamiltonian (1.13) becomes H= 1 2m (p2 x + (py + eBx)2) Because we have manifest translational invariance in the y direction, we can look for energy eigenstates which are also eigenstates of py. These, of course, are just plane waves in the y direction. This motivates an ansatz using the=

with the Hamiltonian, we see that the operator py just gets replaced by its eigenvalue $\hbar k$,

\[Hψk(x, y) = 1 2m (p2 x + (~k + eBx)2) ψx(x, y) ≡ Hkψk(x, y)\]

But this is now something very familiar: it’s the Hamiltonian for a harmonic oscillator in the x direction, with the centre displaced from the origin,

\[Hk = 1 2m p2 x + mω2 B 2 (x + kl2 B)2 \]

=The frequency of the harmonic oscillator is again the
cyloctron frequency ωB = eB/m, and we’ve also introduced a length scale lB. This is a characteristic length scale which governs any quantum phenomena in a magnetic field. It is called the magnetic length. lB = √ eB To give you some sense for this, in a magnetic field of B = 1 Tesla, the magnetic length for an electron is lB ≈ 2.5 × 10−8 m. Something rather strange has happened in the Hamiltonian (1.19): the momentum in the y direction, ~k, has turned into the position of the harmonic oscillator in the x direction, which is now centred at x = −kl2 B. Just as in the algebraic approach above, we’ve reduced the problem to that of the harmonic oscillator. The energy eigenvalues are=
\begin{equation}
E_n = \hbar \omega_B ( n+ \frac{1}{2}  )
    \label{eq:landauee}
\end{equation}

=But now we can also write down the explicit wavefunctions. They depend on two quantum numbers, n ∈ N and k ∈ R,=

\begin{equation}
    ψn,k(x, y) ∼ eikyHn(x + kl2 B )e−(x+kl2 B )2/2l2 B (1.20)
    \label{eq:landauwfs}
\end{equation}

with $H_n$ the usual Hermite polynomial wavefunctions of the harmonic oscillator. The ∼ reflects the fact that we have made no attempt to normalise these these wavefunctions. The wavefunctions look like strips, extended in the y direction but exponentially localised around x = −kl2 =B in the x direction. However, the large degeneracy means that by taking linear combinations of these states, we can cook up wavefunctions that have pretty much any shape you like. Indeed, in the next section we will choose a different A and see very different profiles for the wavefunctions.=

**** Does it check out?

     So, what about our guess at the start of this subsection? Do the plateaux correspond to these energy levels?

     Experimentally, we know that on one of these plateaux the transversal resistivity is
     \[\rho_{xy} = \frac{2\pi\hbar}{e^2} \frac{1}{\nu} \]
     $\nu$ being the /i/s in Figure ref:fig:iqhe.

     From our =rough calculation=, we expect that this conductivity depends on the densitiy of electrons $n$
     \[\rho_{xy}=\frac{B}{ne} \]

     Equating the two, we get
     \begin{equation}
    n=\frac{Be}{2\pi\hbar} \nu
    \label{eq:landaufilling}
\end{equation}
as the number of electrons in unit area.

If we can show that the degeneracy of a Landau level is the same, we would be reasonably assured that the plateaus $\nu$ occur when a $\nu$ Landau levels are exactly filled.
=I HAVE NOT SHOWN ANYTHING=



*** Why are the plateaux at those levels?

Edge modes

[[file:20210302154810-edge_modes_determine_the_values_of_the_iqhe_plateaux.org][edge modes determine the values of the IQHE plateaux]]
#+transclude: t [[file:20210302154810-edge_modes_determine_the_values_of_the_iqhe_plateaux.org][edge modes determine the values of the IQHE plateaux]]

*Edge modes are very important, but sound rather mysterious. However.*
=The fact that something special happens along the edge of a quantum Hall system can be seen even classically. Consider particles moving in circles in a magnetic field. For a fixed magnetic field, all particle motion is in one direction, say anti-clockwise. Near the edge of the sample, the orbits must collide with the boundary. As all motion is anti-clockwise, the only option open to these particles is to bounce back. The result is a skipping motion in which the particles along the one-dimensional boundary move  only in a single direction, as shown in the figure. A particle restricted to move in a single direction along a line is said to be chiral. Particles move in one direction on one side of the sample, and in the other direction on the other side of the sample. We say that the particles have opposite chirality on the two sides. This ensures that the net current, in the absence of an electric field, vanishes=. *This way we can retain a rather simple model*

*Chirality is an interesting property in its own right*
=Having a chiral mode is rather special. In fact, there’s a theorem which says that you can’t have charged chiral particles moving along a wire; there has to be particles which can move in the opposite direction as well. In the language of field theory, this follows from what’s called the chiral anomaly. In the language of condensed matter physics, with particles moving on a lattice, it follows from the Nielsen-Ninomiya theorem. The reason that the simple example of a particle in a magnetic field avoids these theorems is because the chiral fermions live on the boundary of a two-dimensional system, rather than in a one-dimensional wire. This is part of a general story: there are physical phenomena which can only take place on the boundary of a system. This story plays a prominent role in the study of materials called topological insulators=.
*While chiral modes might be an interesting object of study, we wont be focussing on it in much detail.*


=A second reason why chiral modes are special is that it’s hard to disrupt them. If you add impurities to any system, they will scatter electrons. Typically such scattering makes the electrons bounce around in random directions and the net effect is often that the electrons don’t get very far at all. But for chiral modes this isn’t possible simply because all states move in the same direction. If you want to scatter a left-moving electron into a right-moving electron then it has to cross the entire sample. T= *This way the whole system is rather stable*

*How then do we use these facts to calculate the conductivitiy?*
=Let’s now look at what happens when we fill the available states. We do this by introducing a chemical potential. The states are labelled by y-momentum  but, as we’ve seen, this can equally well be thought of as the position of the state in the x-direction. This means that we’re justified in drawing the filled states like this: EF x V(x) From our usual understanding of insulators and conductors, we would say that the bulk of the material is an insulator (because all the states in the band are filled) but the edge of the material is a metal. We can also think about currents in this language. We simply introduce a potential difference ∆μ on the two sides of the sample. This means that we fill up more states on the right-hand edge than on the left-hand edge, like this: EF EF To compute the resulting current we simply need to sum over all filled states. But, at the level of our approximation, this is the same as integrating over x Iy = −e ∫ dk 2π vy(k) = e 2πl2 B ∫ dx 1 eB ∂V ∂x = e 2π ∆μ (2.4) The Hall voltage is eVH = ∆μ, giving us the Hall conductivity σxy = Iy VH = e2 2π~ (2.5) which is indeed the expected conductivity for a single Landau level.= *Nice innit*



***  Wait... why are there plateaux anyways?

    The explanation above shows us why there are plateaux at the levels we see, and even gives us a hint as to why those states would be rather stable, but it has not yet told us /why/ these plateaux persist over a range of values yet, just that something is going on at those values. We have only shown that at complete filled Landau levels ($\nu\in \mathbb{N}$) the longitudinal resistivity $\rho_{xx}=0$ and that the transversal resistivity $\rho_{xy}$ is an integer multiple of the quantum of resistance. However, if we were to move even slightly away from the completely filled Landau state where $B=\frac{ne}{2\pi\hbar}\frac{1}{\nu}$, all our previous arguments hold no water and there is no reason to expect anything already covered to hold.

    This is obviously a problem, as an effect which only shows up at a specific real number would never be experimentally observable. We will need do some dirty work in order for =this= to make sense. In fact, the solution not only requires some dirty work: the solution /is/ dirtiness. 

    Experimental samples are inherently dirty (here meaning: containing other elements than the intended sample[fn:5]), and these impurities require us to re-examine our previous claims somewhat[fn:6]. These impurities lead to two vital insights which will allow us to solve our puzzle:
    1. They (unsurprisingly) break the degeneracy of the Landau levels, resulting in more swept out states as in ref:fig:disorder
    2. They (more surprisingly) turn many /extended/ quantum states into /localized/ ones.


#+caption: Density of states in the IQHE with and without disorder
#+attr_latex: scale=0.75
#+label: fig:disorder
[[./media/broadlandau.png]]


#+caption: Extended to localized states
#+attr_latex: scale=0.75
#+label: fig:extended

[[./media/breakdegen.png]]


This might sound all well and good, but certainly there is a limit to the amount of disorder we are allowed to introduce into our system? Surely the spokes of my bicycle should not be able to serve as Quantum Hall systems.

Correct you are: in general we demand that a) the strength of the disorder (which we model as a random potential) ought to be small relative to the Landau level splitting and b) the disorder does not dramatically vary on small scales, such that for a particle influenced by it the potential can locally be seen as constant.
We can express these as
\begin{equation}
    V_{disorder}<<\hbar\omega_B
    \label{eq:disorderconstraint}
\end{equation}

and
\begin{equation}
    |\Delta V|<<\frac{\hbar \omega_B}{l_B} 
    \label{eq:}
\end{equation}

where $l_B$ is the magnetic length, =roughly the length scale at which these effects are relevant=





=Now consider what this means in a random potential with various peaks and troughs. We’ve drawn some contour lines of such a potential in the left-hand figure, with + denoting the local maxima of the potential and − denoting the local minima. The particles move anti-clockwise around the maxima and clockwise around the minima. In both cases, the particles are trapped close to the extrema. They can’t move throughout the sample. In fact, equipotentials which stretch from one side of a sample to another are relatively rare. One place that they’re guaranteed to exist is on the edge of the sample.= 

=The upshot of this is that the states at the far edge of a band — either of high or low energy — are localised. Only the states close to the centre of the band will be extended. This means that the density of states looks schematically something like the right-hand figure=. 




=Conductivity Revisited For conductivity, the distinction between localised and extended states is an important one. /Only the extended states can transport charge from one side of the sample to the other. So only these states can contribute to the conductivity./ Let’s now see what kind of behaviour we expect for the conductivity. Suppose that we’ve filled all the extended states in a given Landau level and consider what happens as we decrease B with fixed n. Each Landau level can accommodate fewer electrons.=

=But, rather than jumping up to the next Landau level, we now begin to populate the localised states. Since these states can’t contribute to the current, the conductivity doesn’t change. This leads to exactly the kind of plateaux that are observed, with constant conductivities over a range of magnetic field. So the presence of disorder explains the presence of plateaux. But now we have to revisit our original argument of why the resistivities take the specific quantised values (2.3). These were computed assuming that all states in the Landau level contribute to the current. Now we know that many of these states are localised by impurities and don’t transport charge. Surely we expect the value of the resistivity to be different. Right? Well, no. Remarkably, current carried by the extended states increases to compensate for the lack of current transported by localised states. This ensures that the resistivity remains quantised as (2.3) despite the presence of disorder=.


I will leave the more detailed explanation for why the extended states compensate for the localized states for the interested reader, see textcite:Tong2016   









** TODO FQHE in depth

    There are two difficulties however with using lessons from the IQHE in the fqhe effect
The Integer explanation relies on the fact that there are (small) impurities in the sample. However, we know that the FQHE only occurs when the sample is /very/ pure, so the explanation in both cases will likely be different
 The explanation of the IQHE purposefully neglects the interactions electrons have with each other, which is a) unrealistic and b) unneglectable when talking about the FQHE, as it plays a key role in lifting the degeneracy of the Landau states.
 
*** Adding electron interaction

#+transclude: t [[file:20210309161230-iqhe_has_no_electron_interactions_fqhe_does.org][IQHE has no electron interactions, FQHE does]]


#+transclude: t [[file:20210309161322-reasoning_of_fqhe_is_less_rigorous_than_iqhe.org][reasoning of FQHE is less rigorous than IQHE]]

*** TODO The Ugly: Idealizations, Idealizations Everywhere

 Perhaps the most striking difference in the derivation of the FQHE as opposed to the IQHE is the rigour of reasoning used in the former. Unlike its Integer counterpart, the "explanation" much less resembles, well, a derivation, and is better characterized as a "motivation" instead, using a combination of handwaving, squinting at equations and plain stubbornness to finally get a result which is in the same solar system as what we would imagine an proper explanation to be.

 It would do us well to list the most egregious ones first, so they are not able to sneak up on us in the end.

*** TODO Finding the wavefunction

 [[file:20210309164800-the_wavefunction_of_the_fqhe_is_guessed_from_general_grounds.org][The wavefunction of the FQHE is GUESSED from general grounds]]
#+transclude: t [[file:20210309164800-the_wavefunction_of_the_fqhe_is_guessed_from_general_grounds.org][The wavefunction of the FQHE is GUESSED from general grounds]]

 While you might think that quantum mechanics is easy[fn:2], it is actually rather difficult to solve the equations of systems barely larger than a Helium atom. In fact, for most systems we cannot even write down the wavefunction, much less show how it will evolve. The standard solution to these problems is to use  [[file:20210309164701-perturbation_theory.org][perturbation theory]] to find something reasonably close to the actual wavefunction. This works by guessing some test-wavefunction, have it interact with the Hamiltonian plus some slight perturbation, and then ....
 Do this a couple of times and we get reasonably close to the actual wavefunction of the system: a true approximation in the Nortonian sense.

 "Alright", you say, dumbfounded "I guess that's alright. Kind of dissapointing that we don't have the 'actual wavefunction', but I can live with it." Luckily for us, we will not have to settle for the perturbed wavefunction, as we cannot even use perturbation theory here! Recall the insidious italics above: perturbation theory has us treat the disturbance as a /small/ disruption. If we poke the system slightly, we expect it to go relax back to the same state again, which is what allows the above equality ref:eq:perturbation to hold.

 Ideally we would want to use the Hamiltonian of the IQHE and perturb it a little in order to account for the effects of "turning on" the electron interactions. But the electron interaction cannot be modeled as a small perturbation, *as it's too big*: remember that the Landau levels are /wildly/ degenerate, so any additional term is going to multilply considerably, $10^{23}$ considerably. So what now?

*** TODO Writing down the LWF

 This problem was 'solved' by Laughlin in 1982, by instead of even attempting to do the tedious mathematics, he simply wrote down "the" wavefunction of the system. The scare-quotes are not for show this time, as the Laughlin Wavefunction cannot by any measure be said to be the actual one describing the system. Instead, the argument goes, it describes a system which is in the same /equivalence class/ of the actual system. *HOW DO WE KNOW THAT*

 While this may sound silly, Laughlin did not just pull it out of thin air, instead it is more of an educated guess, one which makes some sense.


  Wavefunction is not derived analytically, because hard, and not through perturbation theory because with 10^11 particles perturbations are not small. Instead it is guessed and shown to be similar enough to the actual WF to be useful.
 $N=\frac{AB}{\phi_0}e^-$
 $\hbar\omega_B >> E_{cont}>>V_{disorder}$

 The Laughlin WF only applies to the filling fractions of $\nu=\frac{1}{m}$

*** TODO Step one is admitting you have a problem

 How is it guessed? We need to start with a simplyfying toy model in order to make sense of this, the ol' magnetic annulus. It looks like ...

If we use [[file:20210223170018-symmetry_gauge.org][symmetry gauge]] we get that
\[\hat{\textbf{A}}=-\frac{1}{2} \hat{\textbf{r}}\times \textbf{B} = -\frac{yB}{2}\hat{x}+\frac{xB}{2}\hat{y}
\]

.
.
.

Using these assumptions, if we /insist/ that we are in the lowest Landau Level (LLL), we are able to write down the WFs for /any/ 2 particle wavefunction, regardless of the potential

\begin{equation}
    \Psi(z_1, z_2)= (z_1-z_2)^m e^{-\sum_{i=1}^N |z_i|^2/4l_B^2}
    \label{eq:2pLWF}
\end{equation}
where $m$ is the proportion of the denominator of the filling factor.
Isn't that neat.

 From here Laughlin guessed his WF from two general points of reference:

[[file:20210311183548-every_qh_wf_must_have_the_form_f_z_z1_zn_exp_sum_zi_2.org][Every QH WF must have the form f_z(z1...zn)exp(-sum|zi|2)]]

\begin{equation}
\psi(z_i...z_n)=f(z_i...z_n)e^{-\sum_{i=1}^n\abs{z_i}^2/4l_B^2}
    \label{eq:QHWF}
\end{equation}

with $f(z_i...z_n)$ an analytic function of $z_i$ s, as we do not want our wavefunctions to be nonanalytic.

[[file:20210311183858-every_qh_wf_must_be_antisymmetric.org][
Every QH WF must be antisymmetric]]

The state is describing fermions, so it better be anti-symmetric.

Using this, he wrote down what is now known as the [[file:20210311182300-the_laughlin_wavefunction.org][The Laughlin Wavefunction]]
\begin{equation}
    \psi(z_i)=\prod_{i<q}(z_i-z_j)^m e^{\sum_{i=1}^n \abs{z_i}/4l_B^2}
    \label{eq:LWF}
\end{equation}

Cool.


*** TODO Addional LWF problems

  The LWF is not even an actual ground state of the FQH Hamiltonian, instead from it we derive a Toy Hamiltonian of which the LWF is the ground state, bringing us even further from our goal.



Using these assumptions/idealizations however, we can make it plausible that FQ statistics are happening, I don't think we will use much more.



 From this we arrive at...
\begin{equation}
    \psi(z_i)=\prod_{i<q}(z_i-z_j)^m e^{\sum_{i=1}^n \abs{z_i}/4l_B^2}
    \label{eq:LWF}
\end{equation}


We see that it fulfills both requirements, but is that enough?




*** Excitations

 Excitations

 #+transclude: t :hlevel 5
 Something about the holes

 [[file:20210312122743-excitations_of_the_lwf_ground_state_give_rise_to_quasi_holes_particles.org][Excitations of the LWF Ground State Give Rise to Quasi-holes/particles]]
 #+transclude: t :hlevel 5
 Something about the ground state of the hamiltanian being different




*** Anyons and fractional charge, finally

 At last we are close to discussing anyons again. The key insight that leads to the connection between the two is demonstrating that the quasi-holes and quasi-particles have /fractional charge/ and, finally, fractional statistics. To actually prove that we need to introduce something else entirely, the Berry Phase, but before doing so it is worth it to go through a less technical explanation for why these holes would have fractional charge.

 To see this, let us return to the hole wavefunction

 \begin{equation}
 \Psi_{hole}^\eta(z)=\prod_{i=1}(z_i-\eta)\prod_{k<l}(z_k-z_l)^m e^{-\sum_{i=1}^n \abs{z_i}^2/{4l_B^2}}
     \label{eq:holeLWF}
 \end{equation}
 where, once again, $m$ is the inverse of the [[file:20210223141818-filling_factor.org][filling factor]]  $\nu=1/m$ and $\eta$ the position of the hole. We can generalize this a wavefunction with $M$ holes, as

 \begin{equation}
 \Psi_{M-holes}^\eta(z)=\prod_{j=1}^M\prod_{i=1}^N(z_i-\eta_j)^m\prod_{k<l}(z_k-z_l)^m e^{-\sum_{i=1}^n \abs{z_i}^2/{4l_B^2}}
     \label{eq:mholeLWF}
 \end{equation}
 (note the added exponent after the $z_i-\eta_i$ term)

 The handwavey explanation goes as follows. Say we ignore the Pauli-exclusion principle for as second (as we do not yet know if that even holds for these holes) and we place all of the holes $M$ at one position $\eta$. The wavefunction for this system would look identical to \ref{eq:LWFhole}, except for the added exponent (which you of course noted), like so

 \[
 \Psi_{holes-in-one-spot}^\eta(z)=\prod_{i=1}^N(z_i-\eta)^m\prod_{k<l}(z_k-z_l)^m e^{-\sum_{i=1}^n \abs{z_i}^2/{4l_B^2}}
 \]
 If we squint our eyes a bit, the parameter $\eta$ could look like a variable instead, describing a particle rather than simply a position of the hole(s). If that is the case, however, $\eta$ would just work like another $z_l$ , an electron of charge $-e$
 . However, since it's not, we can infer that it's simply the normal Laughlin WF minus one electron. Then, since there are $m$ electrons, we say that a hole has charge $+e/m$.

 Now, there are a lot of holes in this argument, most prominently us conveniently discarding the Pauli-exclusion principle. This could however be forgiven by pointing at the plasma analogy again (as we shall see in a bit) and say that they will act like a single particle if close together. Furthermore, the argument does not work perfectly, as while $m$ holes look like the absence of one electron, this does not mean that every hole has the same charge.

 To get a more satisfactory and concrete answer we will have to calculate the fractional charge the hard way, using the Berry Connection. While we need to introduce some more *things*, this will also allow us to /finally/ calculate the statistics of the particle, and, as a bonus, it also helps us make sense of the [[file:20210223172322-aharonov_bohm_effect.org][Aharonov Bohm Effect]].

*** Berry phase
# #+transclude: t :hlevel 5
# [[file:20210312130104-berry_connection.org][Berry Connection]]

The Berry phase is the phase that a particle picks up when it is "around" in one of its eigenstates by varying the /parameters/ of the hamiltonian from and back to the eigenstate again. The parameters are usually not the first thing we consider when writing down the Hamiltonian, but could be thought of as, for instance, the specific settings used to prepare the system. Varying these settings slightly (such as the temperature or something) might still keep the system in the same eigenstate, loosely similar to how many statistical mechanical micro-states could give rise to the same macrostate.

Continuing that analogy, if we do this slow enough, the [[file:20210223171329-adiabatic_theorem_quantum.org][adiabatic theorem (quantum)]] guarantees that the system will stay in its eigenstate.[fn:1]

If we do this, after moving the Berry phase back the system will have incurred a phase, the [[file:20210223170728-berry_phase.org][Berry phase]]

*** Berry Connection






* Geometric Anyon phase

 Above we have seen the /topological/ explanation for the anyon phase, but, clearly, it leaves something to be desired: the idealization of 2D space/simply connectedness is too strong, demanding us to change the way we look at the world completely. Furthermore, it is not exactly satisfying, as while it does provide some base level explanation for the effect, it introduces another mystery similar to the Aharonov-Bohm Effect: either we have a real experiment instantiatiating a fictitious system, or we have no explanation for when exactly anyons would show up.

That is why we have been looking at the FQHE up until now, as this is one of the areas where the anyonic phase is said to show up. Moreover, the FQHE gives us the physical tools to calculate the phase in a different way: geometrically.

** Geometric phase explanation

   Although not everyone agrees, the AB effect can for instance be explained geometrically rather than topologically. With this I mean that the phase arises because of /geometric features/ such as curvature rather than out of /topological features/ such as the connectedness. Topological explanation discard all features with are not topologically invariant, which are the features of a space that remain the same under homeomorphisms. This is partially what leads to the mystery of the anyonic phase, as topological explanations, dealing only with objects that "can be continuously deformed into each other" are rather "all or nothing": ALL loops can either be deformed to a point or not.

   Luckily there is a possibility to calculate the phase geometrically, through the aptly named [[file:20210511130045-geometric_phase.org][Geometric Phase]]. The geometric phase is based on the geometry ("curvature") rather than the topology ("connectedness") of the space we will be able to calculate a phase with a continuous dependence on some parameters, rather than the discrete dependence on the connectedness in the topological explanation.

*** Brief history

Theoretical phases have studied geometric phases since around the 1950s, most prominently by  Parachtnam and Kato who showed that ... something with light.

    Howeventually cite:Berry1984.

*** What is phase

    A quantum system, being represented by a wave function, can just like regular ol' sinus waves be described in terms of its amplitude, period, and /phase/, which is, crudely put, the offset with respect to the origin. In quantum mechanics this is almost always described using the [[file:phase_factor.org][Phase factor]] $e^{i\theta}$.

    A simple illustration will help.

    Say our fictional quantum mechanical system is described as $\psi(x,t)=\sin(x-t2\pi)$. After evolving for $t=0.25$, it will always acquire a /dynamical/ phase factor related to time.

    # Normally this is related to the energy but for now it isn't because we haven't defined.

    At $x=0$, $\psi(t=0)=0$, while at $\psi(t=0.25)=1$. We can express this using the phase factor $e^{i\theta}$, with $\theta=1/4\pi$, which we can write as
    \[\psi(t=0.25)=e^{i\pi/2}\psi(t=0)=e^{i\pi/4}sin(x)=.......\]

    The point is that we can generally do this, that the phase factor is dependent on time alone.

*** Geometrical phase

    Berry (and others) discovered that, under certain conditions, this dynamical phase factor is not the /only/ contribution to the total phase, but the state also acquires a /geometrical phase factor/, which, as the name suggests, is due to the geometry of something. The most straightforward "thing" whose geometry would influence phase would be the geometry of spacetime itself, but actually it's much more general than that.

    In general, we say that a quantum state picks up a geometrical phase factor when it is transported /adiabatically/ from one point in parameter space to another. This means that we do things very slowly such as not to make the state go into a different eigenstate. With /parameter space/ we mean the space of all possible values some parameter of the Hamiltonian can take. This can be many different things, we just have to make sure to move everything slowly so the system remains in the same eigenstate.

    Some examples for these parameters include position, the strength of an external magnetic field, the specific settings for a Stern-Gerlach measuring apparatus, the direction of an electric field, etc. The easiest to visualize and most important for our purposed is the physical position of the particles, as the path in parameter space then simply is the path the particles take in physical space, and since the phase we are studying is the phase particles pick up under exchange, which happens in real space.

*** How does geometrical phase get there

As Berry said in his original paper, the occurence of the geometrical phase does indeed appear quite "magical"cite:Berry1984. However, as cite:Simon1983 soon thereafter elucidated, the Berry phase becomes a whole lot less mysterious once we link it to a more general geometric property: [[file:20210511110305-holonomy.org][Holonomy.]]

Holonomy is the phenomenon of a vector (or more generally any mathematical object) not remaining completely invariant after being [[file:20210511111338-parallel_transport.org][Parallel transport]]ed along some curved surface. An example is in order.

Say you are at the northpole, looking "south" (every direction is south) along the Greenwhich meridian line. Your field of vision (let's just take the center of it for simplicity) is our vector which we will be parallel transporting. It has a length of approximately 5km (this does not really matter) and is facing wherever you are looking, originating wherever you are standing. We will now only change one of these variables gradually, your position. You start to bravely swim along this meridian, eventually reaching the equator. Since you are already making a fool's journey, you figure you might as well lean into it and add an extra condition: you will never turn during your journey. Meaning that once you reach the equator, instead of turning 90 degrees to face East, you shuffle Eastword across Africa like some sort of stray crab. Once you reach the international date line in the Pacific ocean, you do not stop acting the fool and begin imitating the jellyfish you meet there, swimming backwards on your back in a straight line back to your starting point.

Once you have been certain you returned back to the same spot again, the question now is: which direction are you facing? Given that you never turned around, you might have expected to face England once again. However, to your utter dismay you are still staring down that boring international date line, ocean as far you could see. Despite never turning around, you have ended up turning $180^\circ$ nonetheless! Curse you, geometry!

This extra angle that you picked up on your Oddyssey is a/has something to do with *holonomy*. Holonomy is a rather general property, but in general indicated the failure of parallel transport along a certain manifold, in this case the 2-Sphere (in normal people talk: the surface of a sphere). While this may be shocking to our foolhardy protagonist, there is something deeply intuitive about not ending up facing the same direction here. But being intuitive does not mean easy to explain: all we know for now  that this has something to do with the curvature of the space we are traversing, but .[fn:4]



These two questions and answers are rather handy, and they cite the following two papers as useful
https://physics.stackexchange.com/questions/383281/when-is-the-berry-phase-only-dependent-on-path-topology

https://physics.stackexchange.com/questions/235503/why-is-the-phase-picked-up-during-identical-particle-exchange-a-topological-inva?rq=1

cite:Leinaas1977
cite:Knapp2016



** Geometry? More like


[[file:20210520180604-on_computing_the_geometric_phase_in_the_fqhe.org][On computing the geometric phase in the FQHE]]
#+transclude: t [[file:20210520180604-on_computing_the_geometric_phase_in_the_fqhe.org][On computing the geometric phase in the FQHE]]
#+include:  "./20210520180604-on_computing_the_geometric_phase_in_the_fqhe.org" :minlevel 3
















* Footnotes
[fn:6] The non-dirty sample just discussed is a great example of taking an idealization too seriously: we cannot explain the phenomena in the idealized setting, and have to retrofit extra physics on top of the idealization in order to get a satisfying explanation, only for us to then show in the limit of no impurities we regain our initial idealization. If this limit would not have been smooth (it fortunately is), we would have wasted all this time!  

[fn:5] Improved performance of impure 2D materials is an active area of research in material science, see cite:Wang2020 for a summary of how impurities enhance the conductivity of graphene. 
[fn:4] Instead imagine taking this same journey in your backyard: walking 5 steps foward, then walking 5 steps with a ninety degree angle to your left, then walking 5 steps back. While you will not end up in the same place (instead unsurprisingly ending up 5 steps to your left), you will still be facing the same direction.

[fn:3] The spin-statistics theorem is only provable in relativistic quantum mechanics. In this thesis we will almost exclusively work in non-relativistic quantum mechanics, which means that this relation is an assumption.
[fn:2] You probably did not think this.

[fn:1] Catch is that the varying of the parameters should not induce a degeneracy in the specific eigenstate.
